# HighloadArchitectureCourseWork

## 1. Выбор темы

В качестве темы был выбран сервис облачного хранения данных по типу [Dropbox](https://www.dropbox.com/) или [Yandex.Disk](http://disk.yandex.ru/).
У сервиса должны быть функции, такие как:

* загрузить файл
* удалить файл
* посмотреть информацию о файле
* поиск по директории
* поделиться ссылкой на файл

## 2. Определение возможного диапазона нагрузок

Положим количество пользователей сервиса равным 5М. Сервис будет ориентирован на аудиторию России.
В связи с этим получаем, что примерно **60%** населения России проживает в часовых поясах -1, 0, +1, +2 и +4 относительно Московского региона,
который в свою очередь находится в зоне GMt+3.

Сервис будет предоставлять **4гб** дискового пространства для бесплатного аккаунта, **100гб** для платного.
Ограничим объем загружаемых и скачиваемых данных для пользователя за день размером в **200%** от его дискового пространства,
т.е. **8гб/день** для бесплатного аккаунта, **200гб/день** для платного.
Также положим, что **96%** пользователей сервиса имеют бесплатный аккаунт, а **4%** будут иметь платную подписку, т.е. платный аккаунт.
Исходя из этого, получмем следующие данные:

|account type|storage|percentage|daily traffic|total storage size                             |total daily traffic                                        |
|------------|-------|----------|-------------|-----------------------------------------------|-----------------------------------------------------------|
|free        |4GB    |96%       |8GB/day      |4GB * 0.96 * 5 * 10^6 = 76.8 * 10^6 GB = 19.2PB|38.4PB/day ~ 444.5GB/sec = 3 556 Gbit/sec ~= 3.556 Tbit/sec|
|paid        |100GB  |4%        |200GB/day    |100GB * 0.04 * 5 * 10^6 = 80 * 10^6GB = 20PB   |40PB/day ~ 463GB/sec = 3 704 Gbit/sec ~=  3.704 Tbit/sec   |

Из рассчетов получаем, что суммарных объем хранилища должен составлять 39.2PB.

Из данных [similarweb](https://www.similarweb.com/website/disk.yandex.ru/) и [tokar.ua](https://tokar.ua/read/9412) можно получить, что:

* средняя продолжительность пребывания на сайте такого проекта около 5 минут
* количество посещений на сайт примерно в 15 раз больше, чем количество пользователей, т.е. пользователь в среднем посещает ресурс 15 раз за месяц

## 3. Выбор планируемой нагрузки

Введём некоторые допущения исходя из-за некоторой нехватки данных и отсутствия исследований рынка на эту тему. Итак:

* Экономика таких сервисов строится на том, что пользователи в среднем используют примерно **50%** своего доступного места
* Пользователь обновляет в среднем где-то **30%-50%** от своего свободного места в год, остальной контент остаётся неизменным
Для рассчета будет все измерять в изображениях и фото, т.к. в основном такие сервисы используются для загрузки фото и медиа контента пользователей
Положим средний размер изображения в **2МБ**, а обновление контента пусть будет **50%** от хранимых данных
* Пиковый трафик будет примерно в **4** раза больше, чем средний по рассчету
* Также, обычно траффик на загрузку будет значительно выше, чем на скачивание. Но для простоты рассчёта примем, что они входящий траффик по объему такой же,
как и исходящий
* Хранить чанки файлов мы будем как минимум в двух хранилищах в разных зонах доступности
* Размер чанка будет 2МБ

## 4. Логическая схема базы данных

![Database scheme](img/db_scheme.png)

Табличка share находится в Redis
Все остальные таблички находятся в RocksDB

## 5.физическая системы хранения

В качестве хранения метаданных о файлах пользователей возьмем RocksDB, для хранилища общих ссылок возьмём Redis с репликами.

Хранить метаданные файлов и их расположения мы будем для каждого пользователя в отдельности в [RocksDB](https://rocksdb.org/), т.е. один пользователь это одна база.

RocksDB - это [высокопроизводительная](https://github.com/facebook/rocksdb/wiki/Performance-Benchmarks) встраиваемая open source база данных типа
_key-value_ для быстрых хранилищ (flash and RAM storages), поддерживаемая и разрабатываемая компанией [Facebook](https://www.facebook.com/).
База данных основана на [LSM-деревьях](https://en.wikipedia.org/wiki/Log-structured_merge-tree) и написана на языке C++, поддерживает конкурентный доступ к данным,
в особенности параллельную запись благодаря LSM-деревьям,
т.к. эта структура данных крайне хорошо подходит для [записи с большой пропускной способностью](https://github.com/wiredtiger/wiredtiger/wiki/Btree-vs-LSM).

[Redis](https://redis.io) с парой реплик вполне подойдёт для хранения общих ссылок, т.к. обычно их не так много (исходя из рассчёта на одного пользователя).
Учитывая, что пользователи в основном будут хранить медиаконтент, то скорее всего он будет разбиваться на альбомы/папки и уже будет отдаваться
ссылка на целый альбом. Собственно, поэтому очень грубо примем, что каждый пользователь имеет в среднем **10 общих ссылок**.
Также здесь будем хранить сессии пользователей.

[Minio](https://min.io/) – использование в качестве S3 хранилища для клиентских чанков.

## 6. Прочие технологии (ЯП, протоколы взаимодействия, веб-сервера, ...)

## 7. Рассчет нагрузки и потребного оборудования

Итак, учитывая сказанное в пункте **3** можно сделать несколько рассчетов и получить, что:

* размер хранилища можно сократить в 2 раза, поэтому оно будет занимать 19.6ПБ
* поскольку в год обновляется примерно 50% данных у каждого пользователя, то соответственно за год 9.8ПБ данных загружается на сервер, и учитывая, что пиковая нагрузка может быть как минимум в 4 раза выше, получается, что 9.8ПБ/год ==>> 1.243ГБ/сек. Возьмём с запасом примерно в 3 раза, поэтому будем считать, что входящий
и исходящий трафик это 3ГБ/сек или 24Гбит/сек
* поскольку мы условились, что измерения и рассчеты будут проводиться относительно картинок, то выходит, что на сервер записывается и считывается около 1500 изображений в секунду

Проведём рассчёт, сколько будет весить каждая запись в БД и сколько будет весить вся БД при заявленном числе пользователей.

1 user record  = 8 + 64 + 64 + 1 + 11 = 148Байт
1 shared link  = 36 + 8 + 8 = 52Байт
1 file record  = 8 + 8 + 12 + 256 + 8 + 8 + 8 = 308Байт
1 chunk record = 8 + 8 + 32 * 2(кол-во зон доступности) + 8 = 88Байт

на один загруженный файл приходится 396Байт

Учитывая, что размер хранилища у нас 19.6ПБ, то количество файлов будет около 19.6 * 10^9 МБ / 2  МБ = 9.8 * 10^9.

Итого:

* все записи пользователей будут весить 148 * 5 * 10^6 = 740 * 10^6 байт = 740МБ
* все записи общих ссылок будут весить 52 * 10 (кол-во ссылок на пользователя) * 5 * 10^6 = 2600 * 10^6 байт = 2.6ГБ
* все записи для файлов будут весить 308 * 9.8 * 10^9 = 3018.4ГБ
* все записи для чанков будут весить 88 * 9.8 * 10^9 = 862.4ГБ

Суммарно, для хранения в RocksDB будет требоваться около 4ТБ дискового пространства.

Учитывая, что сессия пользователя это 64 байта UUID + 8 байт = 72 байта ID пользователя, получаем что для них нужно 72 * 5 *10^6 = 360МБ
Т.е. для Redis необходимо около 3ГБ RAM

Соотв выходит, что в секнуду в базы RocsDB записывается около 396 Байт * 1500 = 594КБ. Для такой нагрузки хватит и одного среднего сервера с 4ТБ SSD.
Но мы возьмем 6 SSD по 4ГБ в RAID10 и это даст двухкратное ускорение записи и четырёхкратное ускорение чтения, итоговый размер будет 12 ГБ,
соотв имеем запас в 3 раза.

Для хранения сессий и общих ссылок нам хватит небольшого сервера с 8ГБ RAM.

Используемые материалы:
[raid-calc](http://www.raid-calculator.com/default.aspx)


## 8. Выбор хостинга / облачного провайдера и расположения серверов

Для нужд такого сервиса катастрофически невыгодно пользоваться услугами облачного провайдера, поэтому будем делать всё своё.
Данные пользователей будем хранить в NAS хранилищах.

## 9. Cхема балансировки нагрузки

Будем использовать nginx L7 балансировку.

TODO: днс балансировка по round robin + CARP резервирование

## 10. Oбеспечение отказоустойчивости

## 11. Итог
